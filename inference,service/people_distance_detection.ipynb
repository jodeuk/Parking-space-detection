{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 주차장 자리 개수 감지 및 위험 거리내 사람 알림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모듈 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# Import common libraries\n",
    "import numpy as np\n",
    "import os, cv2, time\n",
    "import torch\n",
    "import json \n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "백본, 모델 로드 및 본넷 좌표, 색상, 거리 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and parameters\n",
    "config_file_path = \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"\n",
    "num_classes = 4  \n",
    "device = \"cuda\"  # Or \"cpu\"\n",
    "\n",
    "# Load configuration and create predictor\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(config_file_path))\n",
    "cfg.MODEL.WEIGHTS = os.path.join(\"/home/elicer/detectron2_custom_dataset/output_yolo3/segmentation/model_final.pth\")  # Path to your trained model\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes  # Set the number of classes (including background)\n",
    "cfg.MODEL.DEVICE = device\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # Custom threshold\n",
    "\n",
    "# 고정된 색상 설정\n",
    "fixed_colors = {\n",
    "    \"Parking Space\": (0, 255, 255),  # Yellow for Parking Space\n",
    "    \"Driveable Space\": (0, 255, 0),  # Green for Driveable Space\n",
    "    \"car\": (255, 0, 0),  # Blue for Car\n",
    "    \"person\": (0, 0, 255)  # Red for Person\n",
    "}\n",
    "\n",
    "# Load bonnet coordinates from JSON file\n",
    "with open(\"/home/elicer/hkheon/service/video2_bonnet_xy.json\", \"r\") as f:\n",
    "    bonnet_coords = json.load(f)[\"bonnet_coordinates\"]\n",
    "\n",
    "# Convert bonnet coordinates to a NumPy array for masking\n",
    "bonnet_polygon = np.array(bonnet_coords, dtype=np.int32)\n",
    "\n",
    "# Register custom dataset with a different name\n",
    "DatasetCatalog.register(\"my_custom_dataset\", lambda: get_custom_dataset_dicts(\"/home/elicer/dataset_sort/merged_labels_yolo/10020000.json\"))\n",
    "MetadataCatalog.get(\"my_custom_dataset\").thing_classes = [\"Parking Space\", \"Driveable Space\", \"car\", \"person\"]\n",
    "\n",
    "# 메타데이터를 초기화하고 색상 설정\n",
    "metadata = MetadataCatalog.get(\"my_custom_dataset\")\n",
    "metadata.thing_colors = [fixed_colors[cls] for cls in metadata.thing_classes]\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Distance calculation parameters\n",
    "H_camera = 120  # 카메라의 실제 높이(cm)\n",
    "focal_length = 500  # 카메라의 초점 거리(픽셀)\n",
    "distance_threshold = 4  # 4미터 이내의 경우 경고 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input, output 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for input and output videos\n",
    "video_path = \"/home/elicer/detectron2_custom_dataset/video/inference/video3.mp4\"\n",
    "output_video_path = \"/home/elicer/detectron2_custom_dataset/video/inference/result/720p/video3_output_server_yolo16.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비디 캡처 객체 초기화 및 코덱 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 캡처 객체 초기화\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video stream or file\")\n",
    "    exit()\n",
    "\n",
    "# 비디오 코덱 및 저장을 위한 설정\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "# Define bonnet area to exclude\n",
    "bonnet_threshold_y = int(height * 0.8)  # 하단 20%를 본넷 영역으로 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비디오 프로세싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 프로세싱 메인 루프\n",
    "while cap.isOpened():\n",
    "    start_time = time.time()  # 시작 시간 기록\n",
    "\n",
    "    ret, frame = cap.read()  # 프레임 읽기\n",
    "    if not ret:\n",
    "        break  # 더 이상 읽을 프레임이 없으면 루프 탈출\n",
    "\n",
    "    # 본넷 영역을 제외한 마스크 적용\n",
    "    mask = np.zeros(frame.shape[:2], dtype=\"uint8\")\n",
    "    mask[:bonnet_threshold_y, :] = 255  # 상단 80%만 활성화\n",
    "\n",
    "    # 현재 프레임에서 객체 탐지 수행\n",
    "    masked_frame = cv2.bitwise_and(frame, frame, mask=mask)  # 본넷 부분을 제외한 프레임으로 예측 수행\n",
    "    outputs = predictor(masked_frame)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "\n",
    "    # 주차공간 탐지를 위한 필터링\n",
    "    parking_spaces = instances[instances.pred_classes == metadata.thing_classes.index(\"Parking Space\")]\n",
    "\n",
    "    # 신뢰도가 90 이상인 \"Parking Space\"만 필터링\n",
    "    parking_spaces = parking_spaces[parking_spaces.scores > 0.9]\n",
    "    num_parking_spaces = len(parking_spaces)\n",
    "\n",
    "    # 결과 시각화 설정\n",
    "    out_frame = frame.copy()\n",
    "\n",
    "    for i in range(len(instances)):\n",
    "        # 신뢰도 계산\n",
    "        confidence = instances.scores[i].item() * 100  # 신뢰도 퍼센트로 변환\n",
    "\n",
    "        # 특정 신뢰도 이상만 출력\n",
    "        if confidence >= 90:\n",
    "            mask = instances.pred_masks[i].numpy()\n",
    "            cls_id = instances.pred_classes[i].item()\n",
    "            label_text = metadata.thing_classes[cls_id]\n",
    "            color = fixed_colors[label_text]\n",
    "\n",
    "            # 마스크 색상으로 채우기\n",
    "            colored_mask = np.zeros_like(out_frame)\n",
    "            for c in range(3):\n",
    "                colored_mask[:, :, c] = mask * color[c]\n",
    "\n",
    "            # 본넷 좌표에 해당하는 부분을 제외한 마스크 적용\n",
    "            cv2.fillPoly(colored_mask, [bonnet_polygon], (0, 0, 0))  # 본넷 좌표에 해당하는 부분은 검정색으로 덮어씀\n",
    "\n",
    "            # 남아 있는 마스크 부분을 영상에 오버레이\n",
    "            out_frame = cv2.addWeighted(out_frame, 1.0, colored_mask, 0.5, 0)\n",
    "\n",
    "            # 본넷 영역과 겹치지 않는 부분만 남긴 마스크 생성\n",
    "            mask_remained = mask.copy().astype(np.uint8)\n",
    "            cv2.fillPoly(mask_remained, [bonnet_polygon], 0)  # 본넷 영역을 0으로 설정\n",
    "\n",
    "            # 남아 있는 마스크를 기반으로 테두리 그리기\n",
    "            contours, _ = cv2.findContours(mask_remained, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cv2.drawContours(out_frame, contours, -1, color, 2)  # 테두리 추가\n",
    "\n",
    "            # 라벨명과 신뢰도를 표시\n",
    "            bbox = instances.pred_boxes[i].tensor.numpy().astype(int)[0]\n",
    "            x, y = bbox[0], bbox[1]  # 좌상단 좌표\n",
    "            text = f\"{label_text}: {confidence:.1f}%\"\n",
    "            cv2.putText(out_frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)  # 글씨 크기 줄임\n",
    "\n",
    "    # FPS 계산\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    fps = 1 / elapsed_time if elapsed_time > 0 else 0\n",
    "\n",
    "    # FPS 및 주차 공간 수를 프레임에 표시\n",
    "    cv2.putText(out_frame, f'FPS: {int(fps)}', (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    cv2.putText(out_frame, f'Parking Spaces: {num_parking_spaces}', (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # 신뢰도 90 이상인 주차공간 위에 화살표 그리기\n",
    "    for box in parking_spaces.pred_boxes:\n",
    "        x_center = int((box[0] + box[2]) / 2)\n",
    "        y_top = int(box[1])\n",
    "\n",
    "        arrow_start = (x_center, y_top - 10)\n",
    "        arrow_end = (x_center, y_top + 20)\n",
    "\n",
    "        cv2.arrowedLine(out_frame, arrow_start, arrow_end, (0, 255, 0), 2, tipLength=0.5)\n",
    "\n",
    "    # 사람에 대한 거리 계산 및 시각화\n",
    "    persons = instances[instances.pred_classes == metadata.thing_classes.index(\"person\")]\n",
    "\n",
    "    for i in range(len(persons)):\n",
    "        bbox = persons.pred_boxes[i].tensor.numpy()[0]\n",
    "        x1, y1, x2, y2 = bbox\n",
    "\n",
    "        # y축 거리 계산 (사람의 바운딩 박스 높이)\n",
    "        person_height_in_pixels = abs(y2 - y1)\n",
    "\n",
    "        # 거리 계산\n",
    "        distance = (H_camera * focal_length) / person_height_in_pixels\n",
    "        distance_m = distance / 100  # cm를 m로 변환\n",
    "\n",
    "        # 거리 정보 표시 제거\n",
    "        xmid = (x1 + x2) / 2\n",
    "        cv2.putText(out_frame, f'{distance_m:.2f} m', (int(xmid), int(y2)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "        # 4미터 이내인 경우 큰 느낌표 표시\n",
    "        if distance_m <= distance_threshold:\n",
    "            # 사람 중심에 동그라미 배경을 갖는 느낌표 그리기\n",
    "            center_x, center_y = int((x1 + x2) / 2), int((y1 + y2) / 2)\n",
    "            radius = 30\n",
    "            cv2.circle(out_frame, (center_x, center_y), radius, (255, 255, 255), -1)  # 흰색 배경\n",
    "\n",
    "            # 느낌표 크기 조정 및 가운데 맞추기\n",
    "            text_size = cv2.getTextSize('!', cv2.FONT_HERSHEY_SIMPLEX, 2, 4)[0]\n",
    "            text_x = center_x - text_size[0] // 2\n",
    "            text_y = center_y + text_size[1] // 2\n",
    "\n",
    "            # 느낌표 표시\n",
    "            cv2.putText(out_frame, '!', (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 4)\n",
    "\n",
    "    # 수정된 프레임을 출력 비디오 파일에 저장\n",
    "    out.write(out_frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"Video processing complete and resources released.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
