{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모듈 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# Import common libraries\n",
    "import numpy as np\n",
    "import os, cv2, time\n",
    "import torch\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and parameters\n",
    "config_file_path = \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"\n",
    "num_classes = 4  \n",
    "device = \"cuda\"  # Or \"cpu\"\n",
    "\n",
    "# Load configuration and create predictor\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(config_file_path))\n",
    "cfg.MODEL.WEIGHTS = os.path.join(\"/home/elicer/detectron2_custom_dataset/output_yolo3/segmentation/model_final.pth\")  # Path to your trained model\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes  # Set the number of classes (including background)\n",
    "cfg.MODEL.DEVICE = device\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # Custom threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "색상 설정, 메타데이터 등록 및 색상 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고정된 색상 설정\n",
    "fixed_colors = {\n",
    "    \"Parking Space\": (0, 255, 255),  # Yellow for Parking Space\n",
    "    \"Driveable Space\": (0, 255, 0),  # Green for Driveable Space\n",
    "    \"car\": (255, 0, 0),  # Blue for Car\n",
    "    \"person\": (0, 0, 255)  # Red for Person\n",
    "}\n",
    "\n",
    "# Register custom dataset with a different name\n",
    "DatasetCatalog.register(\"my_custom_dataset\", lambda: get_custom_dataset_dicts(\"/home/elicer/dataset_sort/merged_labels_yolo/10020000.json\"))\n",
    "MetadataCatalog.get(\"my_custom_dataset\").thing_classes = [\"Parking Space\", \"Driveable Space\", \"car\", \"person\"]\n",
    "\n",
    "# 메타데이터를 초기화하고 색상 설정\n",
    "metadata = MetadataCatalog.get(\"my_custom_dataset\")\n",
    "metadata.thing_colors = [fixed_colors[cls] for cls in metadata.thing_classes]\n",
    "\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비디오 경로 설정, 비디오 코덱 및 저장을 위한 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for input and output videos\n",
    "video_path = \"/home/elicer/detectron2_custom_dataset/video/inference/video3.mp4\"\n",
    "output_video_path = \"/home/elicer/detectron2_custom_dataset/video/inference/result/720p/video3_output_server_yolo16.mp4\"\n",
    "\n",
    "# 비디오 캡처 객체 초기화\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video stream or file\")\n",
    "    exit()\n",
    "\n",
    "# 비디오 코덱 및 저장을 위한 설정\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비디오 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 프로세싱 메인 루프\n",
    "while cap.isOpened():\n",
    "    start_time = time.time()  # 시작 시간 기록\n",
    "\n",
    "    ret, frame = cap.read()  # 프레임 읽기\n",
    "    if not ret:\n",
    "        break  # 더 이상 읽을 프레임이 없으면 루프 탈출\n",
    "\n",
    "    # 현재 프레임에서 객체 탐지 수행\n",
    "    outputs = predictor(frame)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "\n",
    "    # 결과 시각화\n",
    "    out_frame = frame.copy()\n",
    "\n",
    "    # 모든 인스턴스를 시각화\n",
    "    for i in range(len(instances)):\n",
    "        cls_id = instances.pred_classes[i].item()\n",
    "        label_text = metadata.thing_classes[cls_id]\n",
    "\n",
    "        # 마스크 가져오기\n",
    "        mask = instances.pred_masks[i].numpy()\n",
    "\n",
    "        # 통일된 색상 설정\n",
    "        mask_color = fixed_colors[label_text]\n",
    "\n",
    "        # 마스크를 통일된 색상으로 채우기\n",
    "        colored_mask = np.zeros_like(out_frame)\n",
    "        for c in range(3):\n",
    "            colored_mask[:, :, c] = mask * mask_color[c]\n",
    "\n",
    "        # 마스크를 영상에 오버레이\n",
    "        out_frame = cv2.addWeighted(out_frame, 1.0, colored_mask, 0.5, 0)\n",
    "        \n",
    "        # 마스크 테두리 그리기\n",
    "        contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(out_frame, contours, -1, mask_color, 2)  # 테두리 추가\n",
    "\n",
    "        # 라벨명과 신뢰도 가져오기\n",
    "        confidence = instances.scores[i].item() * 100  # confidence를 퍼센트로 변환\n",
    "        text = f\"{label_text}: {confidence:.1f}%\"\n",
    "\n",
    "        # 바운딩 박스 좌표 가져오기\n",
    "        bbox = instances.pred_boxes[i].tensor.numpy().astype(int)[0]\n",
    "        x, y = bbox[0], bbox[1]  # 좌상단 좌표\n",
    "\n",
    "        # 라벨명과 신뢰도를 마스크 색상으로 영상에 표시\n",
    "        cv2.putText(out_frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, mask_color, 2)\n",
    "\n",
    "    # FPS 계산\n",
    "    end_time = time.time()  # 종료 시간 기록\n",
    "    elapsed_time = end_time - start_time\n",
    "    fps = 1 / elapsed_time if elapsed_time > 0 else 0\n",
    "    \n",
    "    # FPS를 프레임에 표시\n",
    "    cv2.putText(out_frame, f'FPS: {int(fps)}', (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    # 수정된 프레임을 출력 비디오 파일에 저장\n",
    "    out.write(out_frame)\n",
    "\n",
    "# 모든 리소스 해제\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"Video processing complete and resources released.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
